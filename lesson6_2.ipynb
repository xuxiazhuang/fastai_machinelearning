{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different random forest interpretation methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence based on tree variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance of the predictions of the trees. Normally the prediction is just the average, this is variance of the trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we’ve done here is to say if there are any groups that we are very unconfident (which could be due to very little observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are trying to determine whether Jeremy is a good risk or a bad risk. Should we loan him a million dollars. And the random forest says “I think he’s a good risk but I’m not at all confident.” And in which case, we might say okay maybe I shouldn’t give him a million dollars. Where else, if the random forest said “I think he’s a good risk and I’m very sure of that” then we are much more comfortable giving him a million dollars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s not something which you can really use so much in a Kaggle context but it’s more like if you are actually putting out some algorithm which is making big decisions that could cost a lot of money, you probably don’t so much care about the average prediction of the random forest but maybe you actually care about the average minus a couple standard deviations (i.e. what’s the worst-case prediction). Maybe there is a whole group that we are unconfident about, so that’s confidence based on tree variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So . rather than just saying what are the top ten, yesterday one of the practicum students asked me about a feature importance where they said “oh, I think these three are important” and I pointed out that the top one was thousand times more important than the second one. So look at the relative numbers here. So in that case, it’s like “no, don’t look at the top three, look at the one that’s a thousand times more important and ignore all the rest.” Your natural tendency is to want to be precise and careful, but this is where you need to override that and be very practical. This thing is a thousand times more important. Don’t spend any time on anything else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So generally what we actually want to know is all other things being equal, what’s the relationship between YearMade and SalePrice. Because if you think about the drivetrain approach idea of the levers, you really want a model that says if I change this lever, how will it change my objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So one of the questions I got this morning was “there’s like a sale ID and model ID, I should throw those away, right? Because they are just IDs.” No. Don’t assume anything about your data. Leave them in and if they turn out to be super important predictors, you want to find out why that is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But then, now I’m at the other end of my project. I’ve done my feature importance, I’ve pulled out the stuff which is from that dendrogram (i.e. redundant features), I’m looking at the partial dependence and now I’m thinking okay is this shape what I expected? So even better, before you plot this, first of all think what shape would I expect this to be. Because it’s always easy to justify to yourself after the fact, oh, I knew it would look like this. So what shape you expect and then is it that shape? In this case, I’d say this is what I would expect. Where else the previous plot is not what I’d expect. So the partial dependence plot has really pulled out the underlying truth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prince: I was thinking this to be more like feature importance, but feature importance is for complete random forest model, and this tree interpreter is for feature importance for particular observation. So let’s say it’a about hospital readmission. If a patient A is going to be readmitted to a hospital, which feature for that particular patient is going to impact and how can we change that. It is calculated starting from the prediction of mean then seeing how each feature is changing the behavior of that particular patient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from treeinterpreter import treeinterpreter as ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
